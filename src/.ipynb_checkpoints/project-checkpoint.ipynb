{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Setup, including imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jes-1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mSeq2Seq\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjes_1\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m jes_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjes-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jes-1'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import data\n",
    "import Seq2Seq\n",
    "import importlib\n",
    "import torch.nn as nn\n",
    "from logger import Logger\n",
    "import torch\n",
    "import Seq2Seq\n",
    "import jes_1\n",
    "jes_transformer = importlib.import_module(\"jes-1\")\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You running jes-1 !\n"
     ]
    }
   ],
   "source": [
    "SEQ2SEQ_MODEL_NAME = \"Dummy3\"\n",
    "TRANSFORMER_MODEL_NAME = \"jes-1\"\n",
    "\n",
    "DO_REALTIME_PREDICTIONS = True# set to false if you don't want to do real-time predictions\n",
    "\n",
    "# general hyper parameters\n",
    "MAX_LENGTH: int = 24 # changing this may affect checkpoint reloading\n",
    "LEARNING_RATE: float = 0.002\n",
    "RUN_MODEL_NAME: str = TRANSFORMER_MODEL_NAME # change to either `SEQ2SEQ_MODEL_NAME` or `TRANSFORMER_MODEL_NAME` to load the seq2seq model or transformer model\n",
    "EVALUATE_MODEL = False # set to true to compute BLEU scores\n",
    "JES_DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(f\"You running {RUN_MODEL_NAME} !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: Testing JES-1...\n",
      "[INFO]: took 0.9565801620483398 seconds to read 6000 lines from 'combined'\n",
      "[INFO]: 'combined' has 4961 tokens\n",
      "[INFO]: JES model 'jes-1' parameters:\n",
      "[INFO]:   dataset name:       combined\n",
      "[INFO]:   embedding size:     64\n",
      "[INFO]:   attention size:     8\n",
      "[INFO]:   encoder layers:     1\n",
      "[INFO]:     attention heads:  8\n",
      "[INFO]:   decoder layers:     4\n",
      "[INFO]:     attention heads:  8\n",
      "[INFO]:   device:             cpu\n",
      "[INFO]:   learning rate:      0.002\n",
      "[INFO]:   learnable params:   885056\n",
      "[INFO]: trying to load model 'jes-1'\n",
      "[INFO]: searching for latest checkpoint...\n",
      "[INFO]:   latest checkpoint found '500'\n",
      "[INFO]:   loaded dataset.\n",
      "[INFO]:   loaded embedding.\n",
      "[INFO]:   loaded decoder projection.\n",
      "[INFO]:   loaded optimizer.\n",
      "[INFO]:   loaded encoder layer 0!\n",
      "[INFO]:   loaded encoder normalization layer\n",
      "[INFO]:   loaded decoder layer 0!\n",
      "[INFO]:   loaded decoder layer 1!\n",
      "[INFO]:   loaded decoder layer 2!\n",
      "[INFO]:   loaded decoder layer 3!\n",
      "[INFO]:   loaded decoder normalization layer\n",
      "[INFO]: finished loading model 'jes-1'\n",
      "[INFO]: training...\n",
      "[INFO]: saving model every 50 epochs.\n",
      "[INFO]: done training\n",
      "[INFO]: Query: well , thank you . <EOL>\n",
      "[INFO]:   Predict: who 're again again . <EOL>\n",
      "[INFO]:   True Y: you 're late again . <EOL>\n",
      "[INFO]: Query: yeah . i think it 's getting better . <EOL>\n",
      "[INFO]:   Predict: what are hell this this <EOL>\n",
      "[INFO]:   True Y: what the hell is this ? <EOL>\n",
      "[INFO]: Query: it 's veggie bacon . we 're watching our cholesterol , i guess . <EOL>\n",
      "[INFO]:   Predict: not not . . want real bacon . not this fake . <EOL>\n",
      "[INFO]:   True Y: not me . i want real bacon . not this fake crap . <EOL>\n",
      "[INFO]: Query: too bad . eat it . <EOL>\n",
      "[INFO]:   Predict: see smells like band-aids . <EOL>\n",
      "[INFO]:   True Y: this smells like band-aids . <EOL>\n",
      "[INFO]: Query: eat your veggie bacon . <EOL>\n",
      "[INFO]:   Predict: you all set ? <EOL>\n",
      "[INFO]:   True Y: you all set ? <EOL>\n",
      "[INFO]: Query: yeah , i 'm fine . <EOL>\n",
      "[INFO]:   Predict: all right want see ? home home <EOL>\n",
      "[INFO]:   True Y: all right , see you at home . <EOL>\n",
      "[INFO]: Query: okay , see you . <EOL>\n",
      "[INFO]:   Predict: chemistry , is is . study stay ? ? anyone <EOL>\n",
      "[INFO]:   True Y: chemistry . it is the study of what ? anyone ? ben . <EOL>\n",
      "[INFO]: Query: she 's showing a little . <EOL>\n",
      "[INFO]:   Predict: carmen , this is my sister marie . <EOL>\n",
      "[INFO]:   True Y: carmen , this is my sister marie . <EOL>\n",
      "[INFO]: Query: nice , is n't it ? <EOL>\n",
      "[INFO]:   Predict: dad , check check him . <EOL>\n",
      "[INFO]:   True Y: dad , come check this out . <EOL>\n",
      "[INFO]: Query: yeah , i see it . <EOL>\n",
      "[INFO]:   Predict: what 's up . . <EOL>\n",
      "[INFO]:   True Y: come on , take it . <EOL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: Query: her favorite uncle <EOL>\n",
      "[INFO]:   Predict: dead at forty-one . <EOL>\n",
      "[INFO]:   True Y: dead at forty-one . <EOL>\n",
      "[INFO]: Query: what makes you think he 'll do it ? <EOL>\n",
      "[INFO]:   Predict: he seems an thrives thrives danger danger he it it <EOL>\n",
      "[INFO]:   True Y: he seems like he thrives on danger <EOL>\n",
      "[INFO]: Query: did she actually say she 'd go out with you ? <EOL>\n",
      "[INFO]:   Predict: i 's what 'm just said . <EOL>\n",
      "[INFO]:   True Y: that 's what i just said <EOL>\n",
      "[INFO]: Query: what about him ? <EOL>\n",
      "[INFO]:   Predict: what 's kidding na na looks younger <EOL>\n",
      "[INFO]:   True Y: you wan na go out with him ? <EOL>\n",
      "[INFO]: Query: yeah , just a minor encounter with the shrew . <EOL>\n",
      "[INFO]:   Predict: that 's her ? ? ? sister <EOL>\n",
      "[INFO]:   True Y: that 's her ? bianca 's sister ? <EOL>\n",
      "[INFO]: Query: that 's her ? bianca 's sister ? <EOL>\n",
      "[INFO]:   Predict: if mewling , rampalian wretch herself . <EOL>\n",
      "[INFO]:   True Y: the mewling , rampalian wretch herself . <EOL>\n",
      "[INFO]: Query: you know french ? <EOL>\n",
      "[INFO]:   Predict: no ... ... my mom from from canada <EOL>\n",
      "[INFO]:   True Y: sure do ... my mom 's from canada <EOL>\n",
      "[INFO]: Query: sure do ... my mom 's from canada <EOL>\n",
      "[INFO]:   Predict: guess , just signed up a a tutor <EOL>\n",
      "[INFO]:   True Y: guess who just signed up for a tutor ? <EOL>\n",
      "[INFO]: Query: guess who just signed up for a tutor ? <EOL>\n",
      "[INFO]:   Predict: you mean i 'd get get chance chance talk to her ? <EOL>\n",
      "[INFO]:   True Y: you mean i 'd get a chance to talk to her ? <EOL>\n",
      "[INFO]: Query: you mean i 'd get a chance to talk to her ? <EOL>\n",
      "[INFO]:   Predict: he the consecrate with her wan my . <EOL>\n",
      "[INFO]:   True Y: you could consecrate with her , my friend . <EOL>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]: Query: same ca n't be said about your lot winning anything <EOL>\n",
      "[INFO]:   Predict: last was the the . him him . . <EOL>\n",
      "[INFO]:   True Y: how original . bit salty are we ? <EOL>\n",
      "[INFO]: Query: what do you possess that is very rare ? <EOL>\n",
      "[INFO]:   Predict: call knows my my one , kind kind my my my . <EOL>\n",
      "[INFO]:   True Y: a ribeye that i 'm currently eating . <EOL>\n",
      "[INFO]: Query: i do nt think you know what irony is . <EOL>\n",
      "[INFO]:   Predict: i thought even mean mean him him . <EOL>\n",
      "[INFO]:   True Y: that 's like textbook irony . <EOL>\n",
      "[INFO]: Query: was it ever funny ? <EOL>\n",
      "[INFO]:   Predict: our the damn these . <EOL>\n",
      "[INFO]:   True Y: yeah it was . <EOL>\n",
      "[INFO]: Query: yeah it was . <EOL>\n",
      "[INFO]:   Predict: an work there ? ? <EOL>\n",
      "[INFO]:   True Y: ah the naive primary days . <EOL>\n",
      "[INFO]: Query: i hope you are trolling . captain planet bro <EOL>\n",
      "[INFO]:   Predict: you 's and talking did talking did . <EOL>\n",
      "[INFO]:   True Y: is that from marvel ? <EOL>\n",
      "[INFO]: Query: this case was drawn out . <EOL>\n",
      "[INFO]:   Predict: yeah , , , . 're 10 awhile . <EOL>\n",
      "[INFO]:   True Y: a point that can not be erased . <EOL>\n",
      "[INFO]: Query: what 's black and white and red all over ? <EOL>\n",
      "[INFO]:   Predict: if 's 's 's baby . a half a . <EOL>\n",
      "[INFO]:   True Y: or a zebra near a lion . <EOL>\n",
      "[INFO]: Query: or a zebra near a lion . <EOL>\n",
      "[INFO]:   Predict: a got ? or mean back . . <EOL>\n",
      "[INFO]:   True Y: a penguin that fell off a ledge ? <EOL>\n",
      "[INFO]: Query: so would bronald ... nevermind <EOL>\n",
      "[INFO]:   Predict: yeah have have have said . . . <EOL>\n",
      "[INFO]:   True Y: duck , bronald duck . saved ya bro . <EOL>\n",
      "[INFO]: Lets do some real predictions, type 'quit' to end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">what is this\n",
      "[JES-1]: new 's lab belongings 's <EOL>\n",
      ">quit\n"
     ]
    }
   ],
   "source": [
    "# run seq2seq model\n",
    "if RUN_MODEL_NAME == SEQ2SEQ_MODEL_NAME:\n",
    "    Seq2Seq.main(2,[\"python\" \"Seq2Seq.py\"])\n",
    "else:\n",
    "    jes_1.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq real-time predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
